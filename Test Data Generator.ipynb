{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9048f562-59fe-41c9-8b35-96974b940c67",
   "metadata": {},
   "source": [
    "**Synthetic Test Data Generator**\n",
    "\n",
    "*Natural Language Processing*:\n",
    "\n",
    "- Parses user descriptions to understand dataset requirements.\n",
    "- Automatically detects field types and data relationships.\n",
    "- Supports flexible schema generation.\n",
    "\n",
    "*AI-Powered Data Generation*:\n",
    "\n",
    "- Uses Hugging Face transformers (DialoGPT/GPT-2) for intelligent text generation.\n",
    "- Generates realistic, diverse synthetic data.\n",
    "- Supports 13+ data types including names, emails, addresses, dates, descriptions, etc.\n",
    "\n",
    "*Professional Gradio Interface*:\n",
    "\n",
    "- Clean, intuitive UI with helpful tips and examples.\n",
    "- Real-time data generation and preview.\n",
    "- Multiple export formats (CSV, JSON, Excel).\n",
    "- Quick example buttons for common use cases.\n",
    "\n",
    "*Technical Implementation*:\n",
    "\n",
    "- Built with Hugging Face pipelines and tokenizers.\n",
    "- GPU acceleration support (falls back to CPU).\n",
    "- Pandas for data manipulation.\n",
    "- Error handling and performance optimization.\n",
    "\n",
    "üéØ *Supported Data Types*\n",
    "\n",
    "- Personal Data: Names, emails, phone numbers, addresses.\n",
    "- Temporal Data: Dates, timestamps.\n",
    "- Numerical Data: Numbers, prices, ratings, quantities.\n",
    "- Text Data: Descriptions, comments, AI-generated content.\n",
    "- Categorical Data: Categories, departments, types.\n",
    "- Technical Data: URLs, IDs, boolean flags.\n",
    "\n",
    "üöÄ *Usage Examples*\n",
    "The tool can generate datasets like:\n",
    "\n",
    "- Customer databases with contact information.\n",
    "- Product catalogs with pricing and descriptions.\n",
    "- Employee records with HR data.\n",
    "- Sales transactions with financial details.\n",
    "- User profiles for testing applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9142dded-b052-4eb1-a5e0-060b98e3922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio transformers pandas torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d0024d5-ff61-4f4e-8a4a-848e4b5b42cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb9dc27a-5aac-4e0c-aa8a-f2203b80da7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f93ed7c-9127-4967-9e7f-39b082b5e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataGenerator:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Synthetic Data Generator with various pipelines and models.\"\"\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # Initialize text generation pipeline\n",
    "        try:\n",
    "            self.text_generator = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=\"microsoft/DialoGPT-medium\",\n",
    "                device=0 if torch.cuda.is_available() else -1,\n",
    "                max_length=100,\n",
    "                do_sample=True,\n",
    "                temperature=0.7\n",
    "            )\n",
    "        except:\n",
    "            # Fallback to a smaller model if GPU memory is limited\n",
    "            self.text_generator = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=\"gpt2\",\n",
    "                device=0 if torch.cuda.is_available() else -1,\n",
    "                max_length=50,\n",
    "                do_sample=True,\n",
    "                temperature=0.7\n",
    "            )\n",
    "        \n",
    "        # Data type generators\n",
    "        self.data_generators = {\n",
    "            'name': self._generate_names,\n",
    "            'email': self._generate_emails,\n",
    "            'phone': self._generate_phones,\n",
    "            'address': self._generate_addresses,\n",
    "            'date': self._generate_dates,\n",
    "            'number': self._generate_numbers,\n",
    "            'text': self._generate_text,\n",
    "            'category': self._generate_categories,\n",
    "            'boolean': self._generate_booleans,\n",
    "            'url': self._generate_urls,\n",
    "            'id': self._generate_ids,\n",
    "            'price': self._generate_prices,\n",
    "            'rating': self._generate_ratings,\n",
    "            'description': self._generate_descriptions\n",
    "        }\n",
    "        \n",
    "        # Sample data pools\n",
    "        self.sample_data = {\n",
    "            'first_names': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace', 'Henry', 'Ivy', 'Jack'],\n",
    "            'last_names': ['Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia', 'Miller', 'Davis', 'Rodriguez', 'Martinez'],\n",
    "            'domains': ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com', 'company.com', 'email.com'],\n",
    "            'streets': ['Main St', 'Oak Ave', 'Pine Rd', 'Cedar Ln', 'Elm Dr', 'Maple Way', 'Park Blvd'],\n",
    "            'cities': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 'San Antonio'],\n",
    "            'states': ['NY', 'CA', 'IL', 'TX', 'AZ', 'PA', 'FL', 'OH', 'GA', 'NC'],\n",
    "            'categories': ['Electronics', 'Clothing', 'Books', 'Home & Garden', 'Sports', 'Toys', 'Beauty', 'Automotive']\n",
    "        }\n",
    "\n",
    "    def parse_dataset_description(self, description: str) -> Dict[str, Any]:\n",
    "        \"\"\"Parse natural language description to extract dataset requirements.\"\"\"\n",
    "        description = description.lower()\n",
    "        \n",
    "        # Extract number of records\n",
    "        num_records = 100  # default\n",
    "        num_match = re.search(r'(\\d+)\\s*(?:records?|rows?|entries?|samples?)', description)\n",
    "        if num_match:\n",
    "            num_records = int(num_match.group(1))\n",
    "        \n",
    "        # Detect field types based on keywords\n",
    "        fields = {}\n",
    "        \n",
    "        # Common field patterns\n",
    "        field_patterns = {\n",
    "            r'names?|customers?|users?|people': 'name',\n",
    "            r'emails?|e-mails?': 'email',\n",
    "            r'phones?|telephone|mobile': 'phone',\n",
    "            r'address|location|street': 'address',\n",
    "            r'dates?|time|birthday|created': 'date',\n",
    "            r'age|quantity|count|amount': 'number',\n",
    "            r'description|comment|review|text|content': 'text',\n",
    "            r'category|type|genre|department': 'category',\n",
    "            r'active|enabled|verified|status': 'boolean',\n",
    "            r'website|url|link': 'url',\n",
    "            r'id|identifier|key': 'id',\n",
    "            r'price|cost|salary|revenue|budget': 'price',\n",
    "            r'rating|score|stars': 'rating'\n",
    "        }\n",
    "        \n",
    "        # Extract specific field mentions\n",
    "        words = description.split()\n",
    "        for i, word in enumerate(words):\n",
    "            for pattern, field_type in field_patterns.items():\n",
    "                if re.search(pattern, word):\n",
    "                    # Try to get field name from context\n",
    "                    field_name = word\n",
    "                    if i > 0 and words[i-1] in ['user', 'customer', 'product', 'item']:\n",
    "                        field_name = f\"{words[i-1]}_{word}\"\n",
    "                    fields[field_name] = field_type\n",
    "        \n",
    "        # If no specific fields detected, create a default schema\n",
    "        if not fields:\n",
    "            if 'user' in description or 'customer' in description or 'person' in description:\n",
    "                fields = {\n",
    "                    'name': 'name',\n",
    "                    'email': 'email',\n",
    "                    'phone': 'phone',\n",
    "                    'address': 'address',\n",
    "                    'created_date': 'date'\n",
    "                }\n",
    "            elif 'product' in description or 'item' in description:\n",
    "                fields = {\n",
    "                    'product_name': 'text',\n",
    "                    'category': 'category',\n",
    "                    'price': 'price',\n",
    "                    'rating': 'rating',\n",
    "                    'description': 'description'\n",
    "                }\n",
    "            else:\n",
    "                fields = {\n",
    "                    'id': 'id',\n",
    "                    'name': 'name',\n",
    "                    'value': 'number',\n",
    "                    'category': 'category',\n",
    "                    'date': 'date'\n",
    "                }\n",
    "        \n",
    "        return {\n",
    "            'num_records': min(num_records, 10000),  # Limit for performance\n",
    "            'fields': fields,\n",
    "            'description': description\n",
    "        }\n",
    "\n",
    "    def _generate_names(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random names.\"\"\"\n",
    "        names = []\n",
    "        for _ in range(count):\n",
    "            first = random.choice(self.sample_data['first_names'])\n",
    "            last = random.choice(self.sample_data['last_names'])\n",
    "            names.append(f\"{first} {last}\")\n",
    "        return names\n",
    "\n",
    "    def _generate_emails(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random email addresses.\"\"\"\n",
    "        emails = []\n",
    "        for _ in range(count):\n",
    "            first = random.choice(self.sample_data['first_names']).lower()\n",
    "            last = random.choice(self.sample_data['last_names']).lower()\n",
    "            domain = random.choice(self.sample_data['domains'])\n",
    "            separator = random.choice(['.', '_', ''])\n",
    "            emails.append(f\"{first}{separator}{last}@{domain}\")\n",
    "        return emails\n",
    "\n",
    "    def _generate_phones(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random phone numbers.\"\"\"\n",
    "        phones = []\n",
    "        for _ in range(count):\n",
    "            area = random.randint(200, 999)\n",
    "            exchange = random.randint(200, 999)\n",
    "            number = random.randint(1000, 9999)\n",
    "            phones.append(f\"({area}) {exchange}-{number}\")\n",
    "        return phones\n",
    "\n",
    "    def _generate_addresses(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random addresses.\"\"\"\n",
    "        addresses = []\n",
    "        for _ in range(count):\n",
    "            number = random.randint(1, 9999)\n",
    "            street = random.choice(self.sample_data['streets'])\n",
    "            city = random.choice(self.sample_data['cities'])\n",
    "            state = random.choice(self.sample_data['states'])\n",
    "            zip_code = random.randint(10000, 99999)\n",
    "            addresses.append(f\"{number} {street}, {city}, {state} {zip_code}\")\n",
    "        return addresses\n",
    "\n",
    "    def _generate_dates(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random dates.\"\"\"\n",
    "        dates = []\n",
    "        start_date = datetime.now() - timedelta(days=365*2)\n",
    "        for _ in range(count):\n",
    "            random_days = random.randint(0, 365*2)\n",
    "            date = start_date + timedelta(days=random_days)\n",
    "            dates.append(date.strftime(\"%Y-%m-%d\"))\n",
    "        return dates\n",
    "\n",
    "    def _generate_numbers(self, count: int) -> List[int]:\n",
    "        \"\"\"Generate random numbers.\"\"\"\n",
    "        return [random.randint(1, 1000) for _ in range(count)]\n",
    "\n",
    "    def _generate_text(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random text using the language model.\"\"\"\n",
    "        texts = []\n",
    "        prompts = [\"The quick\", \"In today's world\", \"Technology has\", \"People often\", \"The future\"]\n",
    "        \n",
    "        for _ in range(count):\n",
    "            try:\n",
    "                prompt = random.choice(prompts)\n",
    "                result = self.text_generator(prompt, max_length=30, num_return_sequences=1)\n",
    "                text = result[0]['generated_text'].replace(prompt, \"\").strip()\n",
    "                if len(text) < 10:\n",
    "                    text = f\"Sample text content number {random.randint(1, 1000)}\"\n",
    "                texts.append(text[:100])  # Limit length\n",
    "            except:\n",
    "                texts.append(f\"Sample text content number {random.randint(1, 1000)}\")\n",
    "        \n",
    "        return texts\n",
    "\n",
    "    def _generate_categories(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random categories.\"\"\"\n",
    "        return [random.choice(self.sample_data['categories']) for _ in range(count)]\n",
    "\n",
    "    def _generate_booleans(self, count: int) -> List[bool]:\n",
    "        \"\"\"Generate random boolean values.\"\"\"\n",
    "        return [random.choice([True, False]) for _ in range(count)]\n",
    "\n",
    "    def _generate_urls(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random URLs.\"\"\"\n",
    "        urls = []\n",
    "        domains = ['example.com', 'test.org', 'sample.net', 'demo.io', 'site.co']\n",
    "        paths = ['home', 'about', 'contact', 'products', 'services', 'blog']\n",
    "        \n",
    "        for _ in range(count):\n",
    "            domain = random.choice(domains)\n",
    "            path = random.choice(paths)\n",
    "            urls.append(f\"https://www.{domain}/{path}\")\n",
    "        return urls\n",
    "\n",
    "    def _generate_ids(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random IDs.\"\"\"\n",
    "        return [f\"ID_{i:06d}\" for i in range(1, count + 1)]\n",
    "\n",
    "    def _generate_prices(self, count: int) -> List[float]:\n",
    "        \"\"\"Generate random prices.\"\"\"\n",
    "        return [round(random.uniform(9.99, 999.99), 2) for _ in range(count)]\n",
    "\n",
    "    def _generate_ratings(self, count: int) -> List[float]:\n",
    "        \"\"\"Generate random ratings (1-5 scale).\"\"\"\n",
    "        return [round(random.uniform(1.0, 5.0), 1) for _ in range(count)]\n",
    "\n",
    "    def _generate_descriptions(self, count: int) -> List[str]:\n",
    "        \"\"\"Generate random product descriptions.\"\"\"\n",
    "        adjectives = ['Amazing', 'High-quality', 'Durable', 'Innovative', 'Premium', 'Efficient']\n",
    "        nouns = ['product', 'item', 'solution', 'device', 'tool', 'service']\n",
    "        \n",
    "        descriptions = []\n",
    "        for _ in range(count):\n",
    "            adj = random.choice(adjectives)\n",
    "            noun = random.choice(nouns)\n",
    "            descriptions.append(f\"{adj} {noun} designed for optimal performance and user satisfaction.\")\n",
    "        \n",
    "        return descriptions\n",
    "\n",
    "    def generate_dataset(self, description: str, output_format: str = \"CSV\") -> Tuple[str, str]:\n",
    "        \"\"\"Generate a synthetic dataset based on description.\"\"\"\n",
    "        try:\n",
    "            # Parse the description\n",
    "            schema = self.parse_dataset_description(description)\n",
    "            \n",
    "            # Generate data\n",
    "            data = {}\n",
    "            for field_name, field_type in schema['fields'].items():\n",
    "                if field_type in self.data_generators:\n",
    "                    data[field_name] = self.data_generators[field_type](schema['num_records'])\n",
    "                else:\n",
    "                    # Default to text if type not recognized\n",
    "                    data[field_name] = self.data_generators['text'](schema['num_records'])\n",
    "            \n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Generate output based on format\n",
    "            if output_format == \"CSV\":\n",
    "                output = df.to_csv(index=False)\n",
    "                filename = \"synthetic_data.csv\"\n",
    "            elif output_format == \"JSON\":\n",
    "                output = df.to_json(orient='records', indent=2)\n",
    "                filename = \"synthetic_data.json\"\n",
    "            else:  # Excel\n",
    "                # For demo purposes, return CSV format\n",
    "                output = df.to_csv(index=False)\n",
    "                filename = \"synthetic_data.csv\"\n",
    "            \n",
    "            # Create summary\n",
    "            summary = f\"\"\"\n",
    "Dataset Generated Successfully!\n",
    "\n",
    "üìä **Dataset Summary:**\n",
    "- Records: {len(df)}\n",
    "- Fields: {len(df.columns)}\n",
    "- Columns: {', '.join(df.columns.tolist())}\n",
    "\n",
    "üîç **Sample Data Preview:**\n",
    "{df.head().to_string(index=False)}\n",
    "\n",
    "üíæ **Output Format:** {output_format}\n",
    "üìÅ **Suggested Filename:** {filename}\n",
    "            \"\"\"\n",
    "            \n",
    "            return output, summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error generating dataset: {str(e)}\"\n",
    "            return \"\", error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d75c957-afaa-4ea9-a4a3-42685cb6f3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0a7e12bfe04afeb8b6695d0df69f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\anaconda3\\envs\\llms\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\priya\\.cache\\huggingface\\hub\\models--microsoft--DialoGPT-medium. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce15de2030ae4fdca64446e27e88c9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f549b49eea954a3db8638ac36b24d4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7affca507dd2465d9c4b5b24c7d4c46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc290d5e4c244626a9b020d869d0ac22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1e4dc0d2364e8d8313c18c4d822c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd733b208de45009d779103f81659fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize the generator\n",
    "generator = SyntheticDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "188b8847-c347-4ac7-8ff2-0f8314d1412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_interface(description, format_choice):\n",
    "    \"\"\"Interface function for Gradio.\"\"\"\n",
    "    if not description.strip():\n",
    "        return \"\", \"Please provide a description of the dataset you need.\"\n",
    "    \n",
    "    output, summary = generator.generate_dataset(description, format_choice)\n",
    "    return output, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24b8a6c6-64c8-410e-a221-3a24a800befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "def create_interface():\n",
    "    \"\"\"Create the Gradio interface.\"\"\"\n",
    "    \n",
    "    with gr.Blocks(title=\"üî¨ Synthetic Test Data Generator\", theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\"\"\"\n",
    "        # üî¨ Synthetic Test Data Generator\n",
    "        \n",
    "        **Generate realistic test data for your applications using AI-powered synthesis!**\n",
    "        \n",
    "        Simply describe the type of dataset you need in natural language, and this tool will:\n",
    "        - üß† Understand your requirements using NLP\n",
    "        - üéØ Generate diverse, realistic data\n",
    "        - üìä Output in your preferred format\n",
    "        - ‚ö° Use Hugging Face models for intelligent text generation\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                description_input = gr.Textbox(\n",
    "                    label=\"üìù Describe Your Dataset\",\n",
    "                    placeholder=\"Example: Generate 500 customer records with names, emails, phone numbers, addresses, and registration dates\",\n",
    "                    lines=4,\n",
    "                    info=\"Describe what kind of data you need. Be specific about fields, data types, and quantity.\"\n",
    "                )\n",
    "                \n",
    "                format_choice = gr.Radio(\n",
    "                    choices=[\"CSV\", \"JSON\", \"Excel\"],\n",
    "                    value=\"CSV\",\n",
    "                    label=\"üìÅ Output Format\",\n",
    "                    info=\"Choose your preferred output format\"\n",
    "                )\n",
    "                \n",
    "                generate_btn = gr.Button(\"üöÄ Generate Dataset\", variant=\"primary\", size=\"lg\")\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"\"\"\n",
    "                ### üí° **Tips for Better Results:**\n",
    "                \n",
    "                **Be Specific:**\n",
    "                - Mention exact field names you want\n",
    "                - Specify the number of records\n",
    "                - Include data types (dates, numbers, text, etc.)\n",
    "                \n",
    "                **Examples:**\n",
    "                - \"100 user profiles with name, email, age, and signup date\"\n",
    "                - \"Product catalog with 200 items including name, category, price, and description\"\n",
    "                - \"Employee records with ID, name, department, salary, and hire date\"\n",
    "                \n",
    "                **Supported Data Types:**\n",
    "                - üë§ Names, emails, phones\n",
    "                - üìç Addresses, locations\n",
    "                - üìÖ Dates and timestamps  \n",
    "                - üí∞ Prices, numbers, ratings\n",
    "                - üìù Text descriptions\n",
    "                - üè∑Ô∏è Categories, boolean flags\n",
    "                - üîó URLs and IDs\n",
    "                \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                summary_output = gr.Markdown(label=\"üìã Generation Summary\")\n",
    "            \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                data_output = gr.Code(\n",
    "                    label=\"üì¶ Generated Dataset\",\n",
    "                    lines=20,\n",
    "                    interactive=True\n",
    "                )\n",
    "        \n",
    "        # Example buttons\n",
    "        gr.Markdown(\"### üéØ Quick Examples:\")\n",
    "        with gr.Row():\n",
    "            example_btns = [\n",
    "                gr.Button(\"üë• Customer Data\", size=\"sm\"),\n",
    "                gr.Button(\"üõçÔ∏è Product Catalog\", size=\"sm\"),\n",
    "                gr.Button(\"üë®‚Äçüíº Employee Records\", size=\"sm\"),\n",
    "                gr.Button(\"üìä Sales Data\", size=\"sm\")\n",
    "            ]\n",
    "        \n",
    "        # Event handlers\n",
    "        generate_btn.click(\n",
    "            fn=generate_data_interface,\n",
    "            inputs=[description_input, format_choice],\n",
    "            outputs=[data_output, summary_output]\n",
    "        )\n",
    "        \n",
    "        # Example button handlers\n",
    "        example_btns[0].click(\n",
    "            lambda: \"Generate 100 customer records with full name, email address, phone number, shipping address, and account creation date\",\n",
    "            outputs=description_input\n",
    "        )\n",
    "        \n",
    "        example_btns[1].click(\n",
    "            lambda: \"Create 200 product entries with product name, category, price, rating, description, and availability status\",\n",
    "            outputs=description_input\n",
    "        )\n",
    "        \n",
    "        example_btns[2].click(\n",
    "            lambda: \"Generate 150 employee records with employee ID, full name, department, job title, salary, hire date, and active status\",\n",
    "            outputs=description_input\n",
    "        )\n",
    "        \n",
    "        example_btns[3].click(\n",
    "            lambda: \"Create 300 sales transaction records with transaction ID, customer name, product name, quantity, unit price, total amount, and sale date\",\n",
    "            outputs=description_input\n",
    "        )\n",
    "        \n",
    "        gr.Markdown(\"\"\"\n",
    "        ---\n",
    "        ### üîß **Technical Features:**\n",
    "        - **AI-Powered**: Uses Hugging Face transformers for intelligent text generation\n",
    "        - **Flexible Schema**: Automatically detects data types from natural language\n",
    "        - **Multiple Formats**: Export as CSV, JSON, or Excel\n",
    "        - **Scalable**: Generate up to 10,000 records per dataset\n",
    "        - **Realistic Data**: Produces believable, diverse synthetic data\n",
    "        - **Open Source**: Built with open-source models and tools\n",
    "        \n",
    "        **Powered by:** Transformers ‚Ä¢ Pandas ‚Ä¢ Gradio ‚Ä¢ PyTorch\n",
    "        \"\"\")\n",
    "    \n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4e843-1c6e-406a-8ed7-765135aa166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:8081\n",
      "* Running on public URL: https://3cddbca8cedf62ae70.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3cddbca8cedf62ae70.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interface = create_interface()\n",
    "interface.launch(\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=8081,\n",
    "    share=True,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856c94a-9b0f-4117-a144-c2b6c6776fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
